{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CZCVy-vwg3AR"
   },
   "source": [
    "Importing required libraries for data and chi square value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "00iBgracso8T"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#for chi square value from table\n",
    "from scipy.stats import chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rN1xKqF784XE"
   },
   "source": [
    "Importing and processing the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Y2CEC-J5tpe"
   },
   "outputs": [],
   "source": [
    "#adding names to attributes\n",
    "att = [\"A1\",\"A2\",\"A3\",\"A4\",\"A5\",\"A6\",\"A7\",\"A8\",\"A9\",\"A10\",\"A11\",\"A12\",\"A13\",\"A14\",\"A15\",\"A16\",\"A17\",\"A18\",\"A19\",\"A20\",\"A21\",\"A22\",\"A23\",\"A24\",\"A25\",\"A26\",\"A27\",\"A28\",\"A29\",\"A30\",\"A31\",\"A32\",\"A33\",\"A34\",\"A35\",\"A36\",\"A37\",\"A38\",\"A39\",\"A40\",\"A41\",\"A42\",\"A43\",\"A44\",\"A45\",\"A46\",\"A47\",\"A48\",\"A49\",\"A50\",\"A51\",\"A52\",\"A53\",\"A54\",\"A55\",\"A56\",\"A57\",\"A58\",\"A59\",\"A60\",\"Class\"]\n",
    "\n",
    "#importing training data\n",
    "t_data = pd.read_csv(r'train.csv',sep=',',index_col=0,header=None)\n",
    "\n",
    "#splitting the sequence of characters into separate attributes\n",
    "df = t_data[1].str.split('',n=60,expand=True)\n",
    "\n",
    "#dropping the index column\n",
    "df.drop([0],inplace=True,axis=1)\n",
    "\n",
    "#adding the labels/classes column to the dataframe\n",
    "df[61]=t_data[2]\n",
    "\n",
    "#adding attribute names to each column\n",
    "df.columns=att"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wRo_i9_j8_IH"
   },
   "source": [
    "To find the major class in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0IOxhsVC5ofB"
   },
   "outputs": [],
   "source": [
    "#finding the major class in initial data\n",
    "parent_class = np.unique(df['Class'])[np.argmax(np.unique(df['Class'],return_counts=True)[1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TgjhwzYBhAxo"
   },
   "source": [
    "Calculating the impurity of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0HDi2VXmRHsO"
   },
   "outputs": [],
   "source": [
    "#function to square a number\n",
    "def square(x):\n",
    "    return x*x\n",
    "\n",
    "#function to calculate impurity given the method and \n",
    "#array of count of labels for an attribute and its value\n",
    "def impurity(method,label_counts):\n",
    "    imp=0\n",
    "\n",
    "    #using gini index\n",
    "    if method==\"gini\":\n",
    "        imp=1-(sum(map(square,label_counts))/square(sum(label_counts)))\n",
    "\n",
    "    #using entropy\n",
    "    elif method==\"entropy\":\n",
    "        for i in range(label_counts.size):\n",
    "            #trying to avoid zeroes to prevent runtime error of log2(0)\n",
    "            if label_counts[i]!=0:\n",
    "                imp=imp+label_counts[i]*np.log2(label_counts[i])\n",
    "        imp = -(imp)\n",
    "\n",
    "    #using mis-classification error\n",
    "    elif method==\"mis\":\n",
    "        imp_d=1-((label_counts[0]**2+label_counts[1]**2+label_counts[2]**2)/sum(label_counts)**2)\n",
    "    else:\n",
    "        pass\n",
    "        \n",
    "    return imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6oOd89Ll9WIO"
   },
   "source": [
    "Calculating the information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RahZOW1t8GMY"
   },
   "outputs": [],
   "source": [
    "#function to calculate information gain given data set and the attribute\n",
    "def information_gain(current_data,col):\n",
    "\n",
    "    #to calculate the count of classes in given data\n",
    "    class_name, class_count = np.unique(current_data['Class'],return_counts=True)\n",
    "\n",
    "    #a temporary dictionary to store the counts of classes\n",
    "    dit={}\n",
    "    for i in range(class_name.size):\n",
    "        dit[class_name[i]]=class_count[i]\n",
    "\n",
    "    #if there is no count of any of the classes,make it as zero\n",
    "    if \"EI\" not in class_name:\n",
    "        dit['EI']=0\n",
    "    if \"IE\" not in class_name:\n",
    "        dit['IE']=0\n",
    "    if \"N\" not in class_name:\n",
    "        dit['N']=0\n",
    "    dit=dict(sorted(dit.items()))\n",
    "\n",
    "    #this gives the count of classes including zeroes\n",
    "    class_count=np.array(list(dit.values()))\n",
    "\n",
    "    #calculating the impurity of given data set using gini index\n",
    "    imp_d=impurity(\"gini\",class_count) #the impurity method is modifiable here\n",
    "\n",
    "    #an array to store the impurities for the subsets of the given data\n",
    "    arr_imp=[]\n",
    "\n",
    "    #dividing the data set based on the attribute values\n",
    "    att_value, att_count = np.unique(current_data[col],return_counts=True)\n",
    "\n",
    "    #for each value of the attribute\n",
    "    for i in att_value:\n",
    "        #calculating the count of classes for each value of the attribute\n",
    "        class_names, class_counts=np.unique(current_data[current_data[col]==i]['Class'],return_counts=True)\n",
    "\n",
    "        #a temporary dictionary to store the counts of classes\n",
    "        di={}\n",
    "        for j in range(class_names.size):\n",
    "            di[class_names[j]]=class_counts[j]\n",
    "\n",
    "        #if there is no count of any of the classes,make it as zero\n",
    "        if \"EI\" not in class_names:\n",
    "            di['EI']=0\n",
    "        if \"IE\" not in class_names:\n",
    "            di['IE']=0\n",
    "        if \"N\" not in class_names:\n",
    "            di['N']=0\n",
    "\n",
    "        di=dict(sorted(di.items()))\n",
    "        class_counts=np.array(list(di.values()))\n",
    "\n",
    "        #calculating the impurities and storing in array of impurities\n",
    "        arr_imp.append(impurity(\"gini\",class_counts))\n",
    "    #calculating the information gain\n",
    "    s=0\n",
    "    for k in range(att_count.size):\n",
    "        s=s+(att_count[k]*arr_imp[k])\n",
    "    ig=imp_d-(s/sum(att_count))\n",
    "\n",
    "    return ig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "83HKFEqN9bBf"
   },
   "source": [
    "Calculating the chi square value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O4doQ24Z8Ias"
   },
   "outputs": [],
   "source": [
    "#function to calculate chi square value and compare with the value from table\n",
    "def chi_square(current_data,col):\n",
    "\n",
    "    #initial chi square value\n",
    "    chi_value=0\n",
    "\n",
    "    #to calculate the count of classes in given data\n",
    "    class_name, class_count = np.unique(current_data['Class'],return_counts=True)\n",
    "\n",
    "    #dividing the data set based on the attribute values\n",
    "    att_value, att_count = np.unique(current_data[col],return_counts=True)\n",
    "\n",
    "    #for each value of the attribute\n",
    "    for i in att_value:\n",
    "        ind=list(att_value).index(i)\n",
    "\n",
    "        #count of the attribute value\n",
    "        value_count=att_count[ind]\n",
    "\n",
    "        #calculating the count of classes for each value of the attribute\n",
    "        class_names, class_counts=np.unique(current_data[current_data[col]==i]['Class'],return_counts=True)\n",
    "\n",
    "        #calculating the real and expected counts of a class for a value of the attribute\n",
    "        for n in range(class_counts.size):\n",
    "            real=class_counts[n]\n",
    "            expected=value_count*class_count[n]/sum(class_count)\n",
    "            chi=square(real-expected)/expected\n",
    "            chi_value+=chi\n",
    "\n",
    "    #calculating the degrees of freedom\n",
    "    dof=(att_value.size-1)*(class_name.size-1)\n",
    "\n",
    "    #calculating chi square value from table using confidence level and dof\n",
    "    chi_table=chi2.ppf(0.99, dof) #confidence level can be 0.0, 0.95, 0.99\n",
    "\n",
    "    #if the calculated value is greater than that of from the table, the split is not random\n",
    "    if chi_value > chi_table:\n",
    "        return True\n",
    "        \n",
    "    #otherwise the split is random and will not be continued\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ereki6079fW-"
   },
   "source": [
    "ID3 Algorithm to build decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7wogbBzZ8TSD"
   },
   "outputs": [],
   "source": [
    "#function to build the decision tree for a given data set\n",
    "def decision_tree(data_set):\n",
    "\n",
    "    #finding the classes exist in given data set\n",
    "    class_names=np.unique(data_set['Class'])\n",
    "\n",
    "    #if all the data belongs to the same class, it returns that class\n",
    "    if class_names.size==1:\n",
    "        return class_names[0]\n",
    "\n",
    "    #if there are no more attributes to choose, it returns the parent node class\n",
    "    elif len(data_set.columns)==1:\n",
    "        return parent_class\n",
    "\n",
    "    else:\n",
    "        #otherwise, the class for the node is the major class in the given data\n",
    "        parent_class = np.unique(data_set['Class'])[np.argmax(np.unique(data_set['Class'],return_counts=True)[1])]\n",
    "\n",
    "        #a temporary dictionary to store the information gain for all attributes\n",
    "        IG={}\n",
    "\n",
    "        #iterating through all the columns of given data\n",
    "        for index,col in zip(range(data_set.columns.size-1),data_set.columns):\n",
    "            #calculating the information gain using the function\n",
    "            IG[col]=information_gain(data_set,col)\n",
    "\n",
    "        #the best attribute with maximum ig is stored in the 'attribute' variable\n",
    "        attribute=max(IG,key=IG.get)\n",
    "\n",
    "        #'tree' is the final dictionary that stores the entire tree\n",
    "        #the attribute is added to the tree\n",
    "        tree={attribute:{}}\n",
    "\n",
    "        #performing the chi square test\n",
    "        if(chi_square(data_set,attribute)):\n",
    "            #if the test passes, the data is split into sub data based on the attribute values\n",
    "            values=np.unique(data_set[attribute])\n",
    "\n",
    "            #for each attribute value\n",
    "            for value in values:\n",
    "                #a new data set to store the sub data\n",
    "                data_set1=data_set[data_set[attribute]==value]\n",
    "\n",
    "                #the attribute is dropped from the sub data as it is already choosen\n",
    "                data_set1=data_set1.drop([attribute],axis=1)\n",
    "\n",
    "                #the sub data is passed to the algorithm again to generate new tree\n",
    "                tree1 = decision_tree(data_set1)\n",
    "\n",
    "                #the new tree is added to the main tree\n",
    "                tree[attribute][value] = tree1\n",
    "            #returns the final decision tree in the form of dictionary\n",
    "            return tree\n",
    "        else:\n",
    "            #if the test fails, it returns the parent node class\n",
    "            return parent_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-K98u8_9pjd"
   },
   "source": [
    "Function to perform prediction of testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q2TRAOTT8aFa"
   },
   "outputs": [],
   "source": [
    "#function to predict the classes for testing data \n",
    "#which takes the sequence of attribute values for a sample and the final tree\n",
    "def prediction(sequence,tree):\n",
    "\n",
    "    #the first attribute from the tree is stored in 'attribute variable'\n",
    "    attribute=list(tree.keys())[0]\n",
    "\n",
    "    #finding the index of this attribute in all the columns of the data set\n",
    "    index_att=att.index(attribute)\n",
    "\n",
    "    #checks if the value at the index in given sequence exists in the values of that attribute in the tree\n",
    "    if sequence[index_att] in list(tree[attribute].keys()):\n",
    "        #if exists, the subtree for that value of the attribute is stored in 'sub_tree'\n",
    "        sub_tree = tree[attribute][sequence[index_att]]\n",
    "        \n",
    "        #checks if the sub_tree is a tree or a class label\n",
    "        if isinstance(sub_tree,dict):\n",
    "            #if it is a tree, the prediction is performed recursively using this sub_tree\n",
    "            return prediction(sequence,sub_tree)\n",
    "        elif sub_tree is not None:\n",
    "            #if it is not a tree, it returns the sub_tree which could be a class label\n",
    "            return sub_tree\n",
    "        else:\n",
    "            #if all the conditions fail, it returns the parent node class\n",
    "            return parent_class\n",
    "    else:\n",
    "        #if the value does not exist in the tree, it returns the parent node class\n",
    "        return parent_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_G0Fuy109wws"
   },
   "source": [
    "Training the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZU-aUjMG8dF4"
   },
   "outputs": [],
   "source": [
    "#passing the main data set to the decision tree function\n",
    "final_tree = decision_tree(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3kmgbkJW902t"
   },
   "source": [
    "Testing the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VGzN72X68hRF"
   },
   "outputs": [],
   "source": [
    "#importing the testing data\n",
    "test_data_set = pd.read_csv(r'test.csv', header=None)\n",
    "\n",
    "#resetting the index\n",
    "test_data_set = test_data_set.reset_index()\n",
    "\n",
    "#passing each row to the prediction function, for all the rows in the data set\n",
    "final_prediction = [[row[0], prediction(row[1], final_tree)] for index,row in test_data_set.iterrows()]\n",
    "\n",
    "#to export the final prediction to a csv file with header names\n",
    "pd.DataFrame(final_prediction).to_csv('prediction.csv', header=[\"id\",\"class\"], index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Decision_Tree.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
